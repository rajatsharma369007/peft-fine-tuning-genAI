{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "Lightweight fine-tuning is one of the most important techniques for adapting foundation models, because it allows you to modify foundation models for your needs without needing substantial computational resources.\n",
    "In this project, I am applying parameter-efficient fine-tuning using the Hugging Face peft library. Hugging Face PEFT allows you to fine-tune a model without having to fine-tune all of its parameters.\n",
    "\n",
    "* PEFT technique: LoRA\n",
    "* Model: AutoModelForSequenceClassification\n",
    "* Evaluation approach: Accuracy\n",
    "* Fine-tuning dataset: ag_news (https://huggingface.co/datasets/fancyzhx/ag_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad3d00",
   "metadata": {},
   "source": [
    "## Loading Hugging Face Dataset\n",
    "\n",
    "AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of activity. (https://huggingface.co/datasets/fancyzhx/ag_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540387f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7548b361a1f4d05a31bd0e4ada785b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 18.6M/18.6M [00:00<00:00, 20.2MB/s]\n",
      "Downloading data: 100%|██████████| 1.23M/1.23M [00:00<00:00, 5.85MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd2bb2a84074bff9ea6f68ce84c67a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1916ce1ba85f4081bc4f0b523bba9a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 5000\n",
      "}), 'test': Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 5000\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the train and test split\n",
    "splits = [\"train\", \"test\"]\n",
    "ds = {split: ds for split, ds in zip(splits, load_dataset(\"ag_news\", split=splits))}\n",
    "\n",
    "# taking a subset of the original data (5000 rows)\n",
    "for split in splits:\n",
    "    ds[split] = ds[split].shuffle(seed=42).select(range(5000))\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading Hugging Face Tokenizer\n",
    "\n",
    "I am using \"distilbert-base-uncased\". This model is a distilled version of the BERT base model. This model is uncased: it does not make a difference between english and English. (https://huggingface.co/distilbert/distilbert-base-uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b4fc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8f88b3c1e7482e9a094c927b19494b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c64d558d5d04cd88b6d413d94189070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf55e3d31dfb4b18bb95e8db8f0526cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a91336f56a14a00a64c2827ecdaee3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eff28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"preprocess the dataset by returning the tokenized examples\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83714287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2774a24da440ca86dc3023289cb62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f276ec110f51422f931b6e3b2499493b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizing the train and test dataset\n",
    "tokenized_ds = {}\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = ds[split].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad93bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7269, 11498, 2135, 6924, 2011, 9326, 4559, 10134, 2031]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validating the tokenizer function\n",
    "tokenized_ds[\"train\"][0][\"input_ids\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d844f",
   "metadata": {},
   "source": [
    "## Loading a Hugging Face foundational model\n",
    "Here I am using the AutoModelForSequenceClassification which has a classification head on top of the model outputs which can be easily trained with the base model. (https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodelforsequenceclassification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade336d23c4e4feb9f2af987e8d492b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# loading a pre-trained model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    num_labels=4,\n",
    "    id2label={0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"},\n",
    "    label2id={\"World\": 0, \"Sports\": 1, \"Business\": 2, \"Sci/Tech\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3f191",
   "metadata": {},
   "source": [
    "In PyTorch, setting param.requires_grad = False is a way to freeze the parameters of a model or a part of a model. This means that the gradients for these parameters will not be computed during backpropagation, and thus, the parameters will not be updated during training. When using a pre-trained model, you may want to keep the pre-trained layers fixed and only train the new layers added for a specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a057c14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=4, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all the parameters in the base model\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdef2dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "673bb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the evaluation metric: Accuracy\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf5077",
   "metadata": {},
   "source": [
    "## Instantiating the foundational model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac2e249",
   "metadata": {},
   "source": [
    "The Trainer class provides an API for feature-complete training in PyTorch, and it supports distributed training on multiple GPUs/TPUs. Trainer goes hand-in-hand with the TrainingArguments class, which offers a wide range of options to customize how a model is trained. Together, these two classes provide a complete training API.\n",
    "\n",
    "Introducing some parameters in the Trainer method for following reasons:\n",
    "* DataCollatorWithPadding: Data collators are objects that will form a batch by using a list of dataset elements as input. To be able to build batches, data collators may apply some processing (like padding). This will dynamically pad the inputs received.\n",
    "* TrainingArguments: TrainingArguments is the subset of the arguments we use in our example scripts which relate to the training loop itself.\n",
    "    * output_dir (str) — The output directory where the model predictions and checkpoints will be written.\n",
    "    * per_device_train_batch_size - This parameter specifies the batch size to be used for training on each individual device (GPU or CPU) when using distributed or parallel training.\n",
    "    * per_device_eval_batch_size - This parameter specifies the batch size to be used for evaluation on each individual device (GPU or CPU) when using distributed or parallel evaluation.\n",
    "    * learning_rate - controls how much to change the model in response to the estimated error each time the model's weights are updated during training\n",
    "    * num_train_epochs - number of times the entire training dataset is passed through the model during the training process.\n",
    "    * weight_decay - refers to a regularization technique used to prevent overfitting. \n",
    "    * evaluation_strategy - evaluation is performed at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c530e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = TrainingArguments(\n",
    "        output_dir = \"./data/news_classification\",\n",
    "        learning_rate = 2e-5,\n",
    "        \n",
    "        per_device_train_batch_size = 16,\n",
    "        per_device_eval_batch_size = 16,\n",
    "        \n",
    "        num_train_epochs = 5,\n",
    "        weight_decay = 0.01,\n",
    "        \n",
    "        evaluation_strategy = \"epoch\",\n",
    "        save_strategy = \"epoch\",\n",
    "        load_best_model_at_end = True,\n",
    "    ),\n",
    "    \n",
    "    train_dataset = tokenized_ds[\"train\"],\n",
    "    eval_dataset = tokenized_ds[\"test\"],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da36f0",
   "metadata": {},
   "source": [
    "## Evaluating the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58aeeddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3892381191253662,\n",
       " 'eval_accuracy': 0.25,\n",
       " 'eval_runtime': 79.6021,\n",
       " 'eval_samples_per_second': 62.812,\n",
       " 'eval_steps_per_second': 3.932}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c700880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indian board plans own telecast of Australia s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stocks Higher on Drop in Jobless Claims A shar...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nuggets 112, Raptors 106 Carmelo Anthony score...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stocks Higher on Drop in Jobless Claims A shar...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REVIEW: 'Half-Life 2' a Tech Masterpiece (AP) ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>China's inflation rate slows sharply but probl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADV: Try Currency Trading Risk-Free 30 Days 24...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OPEC Can Raise Output Capacity by 1 Mln Barrel...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Intel gets off chip speed roller coaster: Tech...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amazon Snaps Up China's Largest Web Retailer (...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  predicted_label\n",
       "0  Indian board plans own telecast of Australia s...      1                0\n",
       "1  Stocks Higher on Drop in Jobless Claims A shar...      2                0\n",
       "2  Nuggets 112, Raptors 106 Carmelo Anthony score...      1                0\n",
       "3  Stocks Higher on Drop in Jobless Claims A shar...      2                0\n",
       "4  REVIEW: 'Half-Life 2' a Tech Masterpiece (AP) ...      3                0\n",
       "5  China's inflation rate slows sharply but probl...      0                0\n",
       "6  ADV: Try Currency Trading Risk-Free 30 Days 24...      2                0\n",
       "7  OPEC Can Raise Output Capacity by 1 Mln Barrel...      2                0\n",
       "8  Intel gets off chip speed roller coaster: Tech...      3                0\n",
       "9  Amazon Snaps Up China's Largest Web Retailer (...      2                0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view some results\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(tokenized_ds[\"test\"])\n",
    "df = df[[\"text\", \"label\"]]\n",
    "\n",
    "# Replace <br /> tags in the text with spaces\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"<br />\", \" \")\n",
    "\n",
    "# Add the model predictions to the dataframe\n",
    "predictions = trainer.predict(tokenized_ds[\"test\"])\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ebcc9c",
   "metadata": {},
   "source": [
    "### Creating a Peft Model\n",
    "The PEFT config specifies the adapter configuration for your parameter-efficient fine-tuning process. The base class for this is a PeftConfig, but this example will use a LoraConfig, the subclass used for low rank adaptation (LoRA)\n",
    "\n",
    "Low-Rank Adaptation (LoRA) is a PEFT method that decomposes a large matrix into two smaller low-rank matrices in the attention layers. This drastically reduces the number of parameters that need to be fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a475ea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(\n",
      "              in_features=768, out_features=768, bias=True\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Identity()\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=4, out_features=768, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (k_lin): Linear(\n",
      "              in_features=768, out_features=768, bias=True\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Identity()\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=4, out_features=768, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (v_lin): Linear(\n",
      "              in_features=768, out_features=768, bias=True\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Identity()\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=4, out_features=768, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (out_lin): Linear(\n",
      "              in_features=768, out_features=768, bias=True\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Identity()\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=4, out_features=768, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): ModulesToSaveWrapper(\n",
      "    (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (modules_to_save): ModuleDict(\n",
      "      (default): Linear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): ModulesToSaveWrapper(\n",
      "    (original_module): Linear(in_features=768, out_features=4, bias=True)\n",
      "    (modules_to_save): ModuleDict(\n",
      "      (default): Linear(in_features=768, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1fdf16",
   "metadata": {},
   "source": [
    "* target_modules - The names of the modules to apply the adapter to. If this is specified, only the modules with the specified names will be replaced.\n",
    "* r - The rank r of the low-rank matrices is a hyperparameter that determines the size of these matrices. Smaller values of r lead to fewer parameters and faster training, while larger values might capture more task-specific information.\n",
    "* task_type - refers to the specific type of task the model is being fine-tuned or adapted for.\n",
    "* lora_alpha - controls the strength of the low-rank adaptation regularization applied during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a LoRA configuration, a subclass used for the low rank adaptation\n",
    "from peft import LoraConfig, TaskType\n",
    "peft_config = LoraConfig(target_modules = [\n",
    "                                        \"q_lin\",\n",
    "                                        \"k_lin\",\n",
    "                                        \"v_lin\",\n",
    "                                        \"out_lin\"],\n",
    "                         r = 4,\n",
    "                         task_type = TaskType.SEQ_CLS,\n",
    "                         lora_alpha = 16\n",
    "                        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the transformer model into PEFT model\n",
    "from peft import get_peft_model\n",
    "lora_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 147,456 || all params: 67,697,672 || trainable%: 0.2178154663870864\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0557fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModulesToSaveWrapper(\n",
       "  (original_module): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (modules_to_save): ModuleDict(\n",
       "    (default): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForSequenceClassification(\n",
      "  (base_model): LoraModel(\n",
      "    (model): DistilBertForSequenceClassification(\n",
      "      (distilbert): DistilBertModel(\n",
      "        (embeddings): Embeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (transformer): Transformer(\n",
      "          (layer): ModuleList(\n",
      "            (0-5): 6 x TransformerBlock(\n",
      "              (attention): MultiHeadSelfAttention(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (q_lin): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Identity()\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (k_lin): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Identity()\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (v_lin): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Identity()\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (out_lin): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Identity()\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "              )\n",
      "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (activation): GELUActivation()\n",
      "              )\n",
      "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pre_classifier): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (classifier): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=768, out_features=4, bias=True)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=768, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1ee6088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA takes in \"labels\", not \"label\" so we need to rename\n",
    "# training and testing sets\n",
    "train_lora = tokenized_ds['train'].rename_column('label', 'labels')\n",
    "test_lora = tokenized_ds['test'].rename_column('label', 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75945a",
   "metadata": {},
   "source": [
    "## Training the Peft Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "894046c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1565' max='1565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1565/1565 23:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.251862</td>\n",
       "      <td>0.648400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.271100</td>\n",
       "      <td>0.897540</td>\n",
       "      <td>0.830800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.271100</td>\n",
       "      <td>0.752858</td>\n",
       "      <td>0.856400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.860800</td>\n",
       "      <td>0.699458</td>\n",
       "      <td>0.859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.723900</td>\n",
       "      <td>0.683833</td>\n",
       "      <td>0.860800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./data/news_classification/checkpoint-313 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/news_classification/checkpoint-626 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/news_classification/checkpoint-939 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/news_classification/checkpoint-1252 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/news_classification/checkpoint-1565 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1565, training_loss=0.9414280218057358, metrics={'train_runtime': 1430.5688, 'train_samples_per_second': 17.476, 'train_steps_per_second': 1.094, 'total_flos': 3368721408000000.0, 'train_loss': 0.9414280218057358, 'epoch': 5.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tuning the model\n",
    "\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = lora_model,\n",
    "    args = TrainingArguments(\n",
    "        output_dir = \"./data/news_classification\",\n",
    "        \n",
    "        learning_rate = 2e-5,\n",
    "        \n",
    "        per_device_train_batch_size = 16,\n",
    "        per_device_eval_batch_size = 16,\n",
    "        \n",
    "        num_train_epochs = 5,\n",
    "        weight_decay = 0.01,\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        save_strategy = \"epoch\",\n",
    "        load_best_model_at_end = True,\n",
    "    ),\n",
    "    \n",
    "    train_dataset = train_lora,\n",
    "    eval_dataset = test_lora,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b4ce5",
   "metadata": {},
   "source": [
    "## Saving the Peft Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4ac6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the peft model\n",
    "lora_model.save_pretrained(\"cls-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e533d0",
   "metadata": {},
   "source": [
    "## Loading the saved Peft Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e88970dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification\n",
    "model_lora = AutoPeftModelForSequenceClassification.from_pretrained(\"cls-lora\", \n",
    "                                                                    num_labels = 4,\n",
    "                                                                    id2label = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"},\n",
    "                                                                    label2id = {\"World\": 0, \"Sports\": 1, \"Business\": 2, \"Sci/Tech\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98d5090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model_lora,\n",
    "                  eval_dataset=test_lora)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162d531",
   "metadata": {},
   "source": [
    "## Evaluating the Peft Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.683832585811615,\n",
       " 'eval_runtime': 88.3752,\n",
       " 'eval_samples_per_second': 56.577,\n",
       " 'eval_steps_per_second': 7.072}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating the fine-tuned model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indian board plans own telecast of Australia s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stocks Higher on Drop in Jobless Claims A shar...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nuggets 112, Raptors 106 Carmelo Anthony score...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stocks Higher on Drop in Jobless Claims A shar...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REVIEW: 'Half-Life 2' a Tech Masterpiece (AP) ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>China's inflation rate slows sharply but probl...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADV: Try Currency Trading Risk-Free 30 Days 24...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OPEC Can Raise Output Capacity by 1 Mln Barrel...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Intel gets off chip speed roller coaster: Tech...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amazon Snaps Up China's Largest Web Retailer (...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  predicted_label\n",
       "0  Indian board plans own telecast of Australia s...       1                1\n",
       "1  Stocks Higher on Drop in Jobless Claims A shar...       2                2\n",
       "2  Nuggets 112, Raptors 106 Carmelo Anthony score...       1                1\n",
       "3  Stocks Higher on Drop in Jobless Claims A shar...       2                2\n",
       "4  REVIEW: 'Half-Life 2' a Tech Masterpiece (AP) ...       3                3\n",
       "5  China's inflation rate slows sharply but probl...       0                2\n",
       "6  ADV: Try Currency Trading Risk-Free 30 Days 24...       2                3\n",
       "7  OPEC Can Raise Output Capacity by 1 Mln Barrel...       2                2\n",
       "8  Intel gets off chip speed roller coaster: Tech...       3                3\n",
       "9  Amazon Snaps Up China's Largest Web Retailer (...       2                2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view some results\n",
    "import pandas as pd\n",
    "\n",
    "df_tuned = pd.DataFrame(test_lora)\n",
    "df_tuned = df_tuned[[\"text\", \"labels\"]]\n",
    "\n",
    "# Replace <br /> tags in the text with spaces\n",
    "df_tuned[\"text\"] = df_tuned[\"text\"].str.replace(\"<br />\", \" \")\n",
    "\n",
    "# Add the model predictions to the dataframe\n",
    "predictions = trainer.predict(test_lora)\n",
    "df_tuned[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "df_tuned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06978e",
   "metadata": {},
   "source": [
    "## Comparison between the two models\n",
    "* Baseline vs Fine-tuned (PEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09e7c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85369c12",
   "metadata": {},
   "source": [
    "#### Number of correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a29b92fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhMElEQVR4nO3dfVBVdeLH8Q+IXAG5l9QAWVHZXB8otZEevLU5Uaxo2Ghim+kmlWY6YCmbIpP51M7oWGm6lbZZ0pau5kz2IKvGaj6kNx9oyMccczTYtQvuFlzxp4Byfn/04/y8qa0odPnS+zVzZrznfM853+PMhTeHey9BlmVZAgAAMEhwoCcAAABQXwQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOOEBHoCjaW2tlYnTpxQZGSkgoKCAj0dAABwBSzL0qlTpxQXF6fg4MvfZ2m2AXPixAnFx8cHehoAAOAqlJSUqEOHDpfd3mwDJjIyUtIP/wFOpzPAswEAAFfC5/MpPj7e/j5+Oc02YOp+beR0OgkYAAAM899e/sGLeAEAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYJyQQE8AAJqqzlPzAz0FoMk6PjctoOfnDgwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAONcUMHPnzlVQUJAmTpxorzt79qwyMzPVtm1btW7dWunp6SotLfXbr7i4WGlpaQoPD1d0dLQmT56sc+fO+Y3ZvHmz+vTpI4fDoS5duigvL+9apgoAAJqRqw6Y3bt36/XXX1evXr381k+aNEkff/yxVq9erS1btujEiRMaOnSovf38+fNKS0tTdXW1duzYobffflt5eXmaPn26PebYsWNKS0tTcnKyioqKNHHiRI0ZM0YbNmy42ukCAIBm5KoCprKyUiNHjtQbb7yh6667zl5fUVGhN998U/Pnz9c999yjpKQkLVu2TDt27NDnn38uSfrkk0908OBBvfvuu7r55ps1cOBAPf/883r11VdVXV0tSVqyZIkSEhL00ksvqUePHsrKytKwYcO0YMGCBrhkAABguqsKmMzMTKWlpSklJcVvfWFhoWpqavzWd+/eXR07dpTH45EkeTwe9ezZUzExMfaY1NRU+Xw+HThwwB7z42Onpqbax7iUqqoq+Xw+vwUAADRPIfXdYeXKlfriiy+0e/fui7Z5vV6FhoYqKirKb31MTIy8Xq895sJ4qdtet+2nxvh8Pp05c0ZhYWEXnXvOnDmaNWtWfS8HAAAYqF53YEpKSvT0009r+fLlatWqVWPN6ark5uaqoqLCXkpKSgI9JQAA0EjqFTCFhYUqKytTnz59FBISopCQEG3ZskWLFi1SSEiIYmJiVF1drfLycr/9SktLFRsbK0mKjY296F1JdY//2xin03nJuy+S5HA45HQ6/RYAANA81Stg7r33Xu3bt09FRUX2csstt2jkyJH2v1u2bKmNGzfa+xw+fFjFxcVyu92SJLfbrX379qmsrMweU1BQIKfTqcTERHvMhceoG1N3DAAA8MtWr9fAREZG6qabbvJbFxERobZt29rrR48erezsbLVp00ZOp1MTJkyQ2+1W3759JUn9+/dXYmKiHnnkEc2bN09er1fTpk1TZmamHA6HJGncuHF65ZVXNGXKFD3++OPatGmT3nvvPeXn5zfENQMAAMPV+0W8/82CBQsUHBys9PR0VVVVKTU1Va+99pq9vUWLFlq7dq3Gjx8vt9utiIgIZWRkaPbs2faYhIQE5efna9KkSVq4cKE6dOigpUuXKjU1taGnCwAADBRkWZYV6Ek0Bp/PJ5fLpYqKCl4PA+CqdJ7KXV/gco7PTWuU417p92/+FhIAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADj1CtgFi9erF69esnpdMrpdMrtdmvdunX29rNnzyozM1Nt27ZV69atlZ6ertLSUr9jFBcXKy0tTeHh4YqOjtbkyZN17tw5vzGbN29Wnz595HA41KVLF+Xl5V39FQIAgGanXgHToUMHzZ07V4WFhdqzZ4/uueceDR48WAcOHJAkTZo0SR9//LFWr16tLVu26MSJExo6dKi9//nz55WWlqbq6mrt2LFDb7/9tvLy8jR9+nR7zLFjx5SWlqbk5GQVFRVp4sSJGjNmjDZs2NBAlwwAAEwXZFmWdS0HaNOmjV544QUNGzZM119/vVasWKFhw4ZJkr766iv16NFDHo9Hffv21bp16zRo0CCdOHFCMTExkqQlS5YoJydHJ0+eVGhoqHJycpSfn6/9+/fb5xg+fLjKy8u1fv36K56Xz+eTy+VSRUWFnE7ntVwigF+ozlPzAz0FoMk6PjetUY57pd+/r/o1MOfPn9fKlSt1+vRpud1uFRYWqqamRikpKfaY7t27q2PHjvJ4PJIkj8ejnj172vEiSampqfL5fPZdHI/H43eMujF1x7icqqoq+Xw+vwUAADRP9Q6Yffv2qXXr1nI4HBo3bpzWrFmjxMREeb1ehYaGKioqym98TEyMvF6vJMnr9frFS932um0/Ncbn8+nMmTOXndecOXPkcrnsJT4+vr6XBgAADFHvgOnWrZuKioq0c+dOjR8/XhkZGTp48GBjzK1ecnNzVVFRYS8lJSWBnhIAAGgkIfXdITQ0VF26dJEkJSUlaffu3Vq4cKEeeughVVdXq7y83O8uTGlpqWJjYyVJsbGx2rVrl9/x6t6ldOGYH79zqbS0VE6nU2FhYZedl8PhkMPhqO/lAAAAA13z58DU1taqqqpKSUlJatmypTZu3GhvO3z4sIqLi+V2uyVJbrdb+/btU1lZmT2moKBATqdTiYmJ9pgLj1E3pu4YAAAA9boDk5ubq4EDB6pjx446deqUVqxYoc2bN2vDhg1yuVwaPXq0srOz1aZNGzmdTk2YMEFut1t9+/aVJPXv31+JiYl65JFHNG/ePHm9Xk2bNk2ZmZn23ZNx48bplVde0ZQpU/T4449r06ZNeu+995Sfz7sBAADAD+oVMGVlZRo1apS+/fZbuVwu9erVSxs2bNDvfvc7SdKCBQsUHBys9PR0VVVVKTU1Va+99pq9f4sWLbR27VqNHz9ebrdbERERysjI0OzZs+0xCQkJys/P16RJk7Rw4UJ16NBBS5cuVWpqagNdMgAAMN01fw5MU8XnwAC4VnwODHB5xn4ODAAAQKAQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADBOvQJmzpw5uvXWWxUZGano6GgNGTJEhw8f9htz9uxZZWZmqm3btmrdurXS09NVWlrqN6a4uFhpaWkKDw9XdHS0Jk+erHPnzvmN2bx5s/r06SOHw6EuXbooLy/v6q4QAAA0O/UKmC1btigzM1Off/65CgoKVFNTo/79++v06dP2mEmTJunjjz/W6tWrtWXLFp04cUJDhw61t58/f15paWmqrq7Wjh079PbbbysvL0/Tp0+3xxw7dkxpaWlKTk5WUVGRJk6cqDFjxmjDhg0NcMkAAMB0QZZlWVe788mTJxUdHa0tW7aoX79+qqio0PXXX68VK1Zo2LBhkqSvvvpKPXr0kMfjUd++fbVu3ToNGjRIJ06cUExMjCRpyZIlysnJ0cmTJxUaGqqcnBzl5+dr//799rmGDx+u8vJyrV+//orm5vP55HK5VFFRIafTebWXCOAXrPPU/EBPAWiyjs9Na5TjXun372t6DUxFRYUkqU2bNpKkwsJC1dTUKCUlxR7TvXt3dezYUR6PR5Lk8XjUs2dPO14kKTU1VT6fTwcOHLDHXHiMujF1x7iUqqoq+Xw+vwUAADRPVx0wtbW1mjhxou68807ddNNNkiSv16vQ0FBFRUX5jY2JiZHX67XHXBgvddvrtv3UGJ/PpzNnzlxyPnPmzJHL5bKX+Pj4q700AADQxF11wGRmZmr//v1auXJlQ87nquXm5qqiosJeSkpKAj0lAADQSEKuZqesrCytXbtWW7duVYcOHez1sbGxqq6uVnl5ud9dmNLSUsXGxtpjdu3a5Xe8uncpXTjmx+9cKi0tldPpVFhY2CXn5HA45HA4ruZyAACAYep1B8ayLGVlZWnNmjXatGmTEhIS/LYnJSWpZcuW2rhxo73u8OHDKi4ultvtliS53W7t27dPZWVl9piCggI5nU4lJibaYy48Rt2YumMAAIBftnrdgcnMzNSKFSv04YcfKjIy0n7NisvlUlhYmFwul0aPHq3s7Gy1adNGTqdTEyZMkNvtVt++fSVJ/fv3V2Jioh555BHNmzdPXq9X06ZNU2Zmpn0HZdy4cXrllVc0ZcoUPf7449q0aZPee+895efzjgAAAFDPOzCLFy9WRUWF7r77brVv395eVq1aZY9ZsGCBBg0apPT0dPXr10+xsbF6//337e0tWrTQ2rVr1aJFC7ndbv3hD3/QqFGjNHv2bHtMQkKC8vPzVVBQoN69e+ull17S0qVLlZqa2gCXDAAATHdNnwPTlPE5MACuFZ8DA1ye0Z8DAwAAEAgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwTkigJ2CizlPzAz0FoEk7Pjct0FMA0MxxBwYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHHqHTBbt27V/fffr7i4OAUFBemDDz7w225ZlqZPn6727dsrLCxMKSkpOnLkiN+Y7777TiNHjpTT6VRUVJRGjx6tyspKvzF79+7VXXfdpVatWik+Pl7z5s2r/9UBAIBmqd4Bc/r0afXu3VuvvvrqJbfPmzdPixYt0pIlS7Rz505FREQoNTVVZ8+etceMHDlSBw4cUEFBgdauXautW7dq7Nix9nafz6f+/furU6dOKiws1AsvvKCZM2fqL3/5y1VcIgAAaG5C6rvDwIEDNXDgwEtusyxLL7/8sqZNm6bBgwdLkv76178qJiZGH3zwgYYPH65Dhw5p/fr12r17t2655RZJ0p///Gfdd999evHFFxUXF6fly5erurpab731lkJDQ3XjjTeqqKhI8+fP9wsdAADwy9Sgr4E5duyYvF6vUlJS7HUul0u33367PB6PJMnj8SgqKsqOF0lKSUlRcHCwdu7caY/p16+fQkND7TGpqak6fPiwvv/++0ueu6qqSj6fz28BAADNU4MGjNfrlSTFxMT4rY+JibG3eb1eRUdH+20PCQlRmzZt/MZc6hgXnuPH5syZI5fLZS/x8fHXfkEAAKBJajbvQsrNzVVFRYW9lJSUBHpKAACgkTRowMTGxkqSSktL/daXlpba22JjY1VWVua3/dy5c/ruu+/8xlzqGBee48ccDoecTqffAgAAmqcGDZiEhATFxsZq48aN9jqfz6edO3fK7XZLktxut8rLy1VYWGiP2bRpk2pra3X77bfbY7Zu3aqamhp7TEFBgbp166brrruuIacMAAAMVO+AqaysVFFRkYqKiiT98MLdoqIiFRcXKygoSBMnTtSf/vQnffTRR9q3b59GjRqluLg4DRkyRJLUo0cPDRgwQE888YR27dql7du3KysrS8OHD1dcXJwkacSIEQoNDdXo0aN14MABrVq1SgsXLlR2dnaDXTgAADBXvd9GvWfPHiUnJ9uP66IiIyNDeXl5mjJlik6fPq2xY8eqvLxcv/3tb7V+/Xq1atXK3mf58uXKysrSvffeq+DgYKWnp2vRokX2dpfLpU8++USZmZlKSkpSu3btNH36dN5CDQAAJElBlmVZgZ5EY/D5fHK5XKqoqGjw18N0nprfoMcDmpvjc9MCPYUGwXMduLzGep5f6ffvZvMuJAAA8MtBwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4TTpgXn31VXXu3FmtWrXS7bffrl27dgV6SgAAoAlosgGzatUqZWdna8aMGfriiy/Uu3dvpaamqqysLNBTAwAAAdZkA2b+/Pl64okn9NhjjykxMVFLlixReHi43nrrrUBPDQAABFhIoCdwKdXV1SosLFRubq69Ljg4WCkpKfJ4PJfcp6qqSlVVVfbjiooKSZLP52vw+dVW/U+DHxNoThrjeRcIPNeBy2us53ndcS3L+slxTTJg/v3vf+v8+fOKiYnxWx8TE6OvvvrqkvvMmTNHs2bNumh9fHx8o8wRwOW5Xg70DAA0tsZ+np86dUoul+uy25tkwFyN3NxcZWdn249ra2v13XffqW3btgoKCgrgzNDYfD6f4uPjVVJSIqfTGejpAGgEPM9/OSzL0qlTpxQXF/eT45pkwLRr104tWrRQaWmp3/rS0lLFxsZech+HwyGHw+G3LioqqrGmiCbI6XTyhQ1o5nie/zL81J2XOk3yRbyhoaFKSkrSxo0b7XW1tbXauHGj3G53AGcGAACagiZ5B0aSsrOzlZGRoVtuuUW33XabXn75ZZ0+fVqPPfZYoKcGAAACrMkGzEMPPaSTJ09q+vTp8nq9uvnmm7V+/fqLXtgLOBwOzZgx46JfIQJoPnie48eCrP/2PiUAAIAmpkm+BgYAAOCnEDAAAMA4BAwAADAOAYNmq3Pnznr55Zftx0FBQfrggw8CNh8AZqjv14pHH31UQ4YMabT54NIIGDSKRx99VEFBQfbStm1bDRgwQHv37g3YnL799lsNHDgwYOcHTHDhczc0NFRdunTR7Nmzde7cOUnS5s2b/Z7bFy5er1eSNHPmzEtuX7p06WX3rVvy8vICePUwSZN9GzXMN2DAAC1btkyS5PV6NW3aNA0aNEjFxcUBmc/lPsUZgL+6525VVZX+/ve/KzMzUy1btvT7A7uHDx++6BNxo6Oj7X/feOON+sc//uG3/brrrtOgQYPsxy+++KLWr1/vN+5KPoEVkLgDg0bkcDgUGxur2NhY3XzzzZo6dapKSkp08uRJSVJOTo66du2q8PBw/frXv9Zzzz2nmpoae/8vv/xSycnJioyMlNPpVFJSkvbs2WNv/+yzz3TXXXcpLCxM8fHxeuqpp3T69OnLzufC28LHjx9XUFCQ3n//fSUnJys8PFy9e/e+6K+d1/ccQHNQ99zt1KmTxo8fr5SUFH300Ud+Y6Kjo+3nd90SHPz/31JCQkIu2n7h14TY2Fi1bt36onFhYWGXnFNQUJBef/11DRo0SOHh4erRo4c8Ho++/vpr3X333YqIiNAdd9yho0eP+u23ePFi3XDDDQoNDVW3bt30zjvv+G0/cuSI+vXrp1atWikxMVEFBQUXnbukpES///3vFRUVpTZt2mjw4ME6fvz4Vf7voqEQMPhZVFZW6t1331WXLl3Utm1bSVJkZKTy8vJ08OBBLVy4UG+88YYWLFhg7zNy5Eh16NBBu3fvVmFhoaZOnaqWLVtKko4ePaoBAwYoPT1de/fu1apVq/TZZ58pKyurXvN69tln9cwzz6ioqEhdu3bVww8/bN8qb6hzAKYLCwtTdXV1oKeh559/XqNGjVJRUZG6d++uESNG6Mknn1Rubq727Nkjy7L8np9r1qzR008/rT/+8Y/av3+/nnzyST322GP69NNPJf3wJ2qGDh2q0NBQ7dy5U0uWLFFOTo7fOWtqapSamqrIyEht27ZN27dvV+vWrTVgwIAm8X/yi2YBjSAjI8Nq0aKFFRERYUVERFiSrPbt21uFhYWX3eeFF16wkpKS7MeRkZFWXl7eJceOHj3aGjt2rN+6bdu2WcHBwdaZM2csy7KsTp06WQsWLLC3S7LWrFljWZZlHTt2zJJkLV261N5+4MABS5J16NChKz4H0NxkZGRYgwcPtizLsmpra62CggLL4XBYzzzzjGVZlvXpp59akuzndt2SmJhoH2PGjBlWcHCw3/Zbb731onPNmDHD6t279xXNS5I1bdo0+7HH47EkWW+++aa97m9/+5vVqlUr+/Edd9xhPfHEE37HefDBB6377rvPsizL2rBhgxUSEmL961//srevW7fO72vFO++8Y3Xr1s2qra21x1RVVVlhYWHWhg0bLvo/w8+H18Cg0SQnJ2vx4sWSpO+//16vvfaaBg4cqF27dqlTp05atWqVFi1apKNHj6qyslLnzp3z+516dna2xowZo3feeUcpKSl68MEHdcMNN0j64ddLe/fu1fLly+3xlmWptrZWx44dU48ePa5ojr169bL/3b59e0lSWVmZunfv3mDnAEyzdu1atW7dWjU1NaqtrdWIESM0c+ZMvzHbtm1TZGSk/bju7midbt26+f3aqSH+BMCFz9e6PyvTs2dPv3Vnz56Vz+eT0+nUoUOHNHbsWL9j3HnnnVq4cKEk6dChQ4qPj1dcXJy9/cd/MPjLL7/U119/7XetknT27NmLfl2FnxcBg0YTERGhLl262I+XLl0ql8ulN954Q2lpaRo5cqRmzZql1NRUuVwurVy5Ui+99JI9fubMmRoxYoTy8/O1bt06zZgxQytXrtQDDzygyspKPfnkk3rqqacuOm/Hjh2veI4XftENCgqS9MNtZUkNdg7ANHU/fISGhiouLk4hIRd/q0hISFBUVNRlj1H3DqaGdKnn6089hxtCZWWlkpKS/H6QqXP99dc32HlQfwQMfjZBQUEKDg7WmTNntGPHDnXq1EnPPvusvf2bb765aJ+uXbuqa9eumjRpkh5++GEtW7ZMDzzwgPr06aODBw82+BfIC/0c5wCaoh//8GGqHj16aPv27crIyLDXbd++XYmJifb2kpISffvtt/Yd2M8//9zvGH369NGqVasUHR190buuEFi8iBeNpqqqSl6vV16vV4cOHdKECRNUWVmp+++/X7/5zW9UXFyslStX6ujRo1q0aJHWrFlj73vmzBllZWVp8+bN+uabb7R9+3bt3r3b/rVNTk6OduzYoaysLBUVFenIkSP68MMPG/QFtj/HOQBTlZWV2c/vuuXCdxE2BZMnT1ZeXp4WL16sI0eOaP78+Xr//ff1zDPPSJJSUlLUtWtXZWRk6Msvv9S2bdv8fqiSfngzQbt27TR48GBt27ZNx44d0+bNm/XUU0/pn//8ZyAuC/+HOzBoNOvXr7d/qomMjFT37t21evVq3X333ZKkSZMmKSsrS1VVVUpLS9Nzzz1n/569RYsW+s9//qNRo0aptLRU7dq109ChQzVr1ixJP/wufMuWLXr22Wd11113ybIs3XDDDXrooYcabP4/xzkAU3Xr1u2idR6PR3379g3AbC5tyJAhWrhwoV588UU9/fTTSkhI0LJly+yvQcHBwVqzZo1Gjx6t2267TZ07d9aiRYs0YMAA+xjh4eHaunWrcnJyNHToUJ06dUq/+tWvdO+993JHJsCCLMuyAj0JAACA+uBXSAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOP8LwOgBfnSdWwRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\"Baseline\":(df.label == df.predicted_label).sum(), \"PEFT model\":(df_tuned.labels == df_tuned.predicted_label).sum()}\n",
    "plt.bar(data.keys(), data.values());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb5080",
   "metadata": {},
   "source": [
    "#### Number of incorrectly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eafbefe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\"Baseline\":(df.label != df.predicted_label).sum(), \"PEFT model\":(df_tuned.labels != df_tuned.predicted_label).sum()}\n",
    "plt.bar(data.keys(), data.values());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d531f7",
   "metadata": {},
   "source": [
    "#### Evaluation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf22158e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\"Baseline\":1.3892, \"PEFT model\":0.6838}\n",
    "plt.bar(data.keys(), data.values());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a228bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
